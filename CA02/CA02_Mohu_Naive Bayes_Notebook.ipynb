{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02_Mohu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeY9X3Q6UaU-",
        "colab_type": "text"
      },
      "source": [
        "#CA02: Spam e-Mail Detection using Naive Bayes Classification Algorithm\n",
        "\n",
        "In this exercise we shall train the model with set of emails labelled as either from Spam or Not Spam. There are 702 emails equally divided into spam and non spam category. Next, we shall test the model on 260 emails. We shall ask model to predict the category of this emails and compare the accuracy with correct classification that we already know."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvk2HDdtaMCg",
        "colab_type": "text"
      },
      "source": [
        "# Importing the necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88jRLyLoUPYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing necessary modules \n",
        "#to create, change or  move directory\n",
        "import os\n",
        "import numpy as np \n",
        "\n",
        "#A Counter is a dict subclass for counting hashable objects\n",
        "from collections import Counter \n",
        "\n",
        "#importing the Naive Bayes algorithm module Gaussian which is used in classification; it assumes that features follow normal distribution\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "#In multilabel classification, this function computes subset accuracy\n",
        "from sklearn.metrics import accuracy_score \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS_n0K6DaXal",
        "colab_type": "text"
      },
      "source": [
        "### Setting the Current Directory Path\n",
        "\n",
        "Mounting the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO17W9l4QokB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d58c1b6-dd30-4834-ceef-55c6e37920a4"
      },
      "source": [
        "#mounting the google drive folder in case it returns an error\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = '/content/drive/My Drive/MSBA_Colab_2020/ML Algorithms/Naive_Bayes'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km93FR1oYfLq",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 - Cleaning and Preparing the Data \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruc_x1q57UnC",
        "colab_type": "text"
      },
      "source": [
        "Code to remove the non essential , repititive words and store it as a list using for loops in a function named new_Dict\n",
        "\n",
        "Below is the description of the functions used in the code beow\n",
        "\n",
        "*   Counter() - A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.\n",
        "*   .most_common() - Return a list of the n most common elements and their counts from the most common to the least\n",
        "\n",
        "\n",
        "*   os.listdir() -returns a list of items contained in the path\n",
        "\n",
        "* os.path.join() - joins two or more directory paths. It is used to access the emails contained in the given directory folder in the google drive  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxvwEpQ7SoOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function builds a Dictionary of most common 3000 words from all the email content.\n",
        "# First it adds all words and symbols in the dictionary. \n",
        "#Then it removes all non-alpha-numeric characters and any single character alpha-numeric characters. \n",
        "#After this is complete it shrinks the Dictionary by keeping only most common 3000 words in the dictionary. \n",
        "#It returns the Dictionary\n",
        "\n",
        "#create a function named 'new_Dict' to store all the common 3000 words from emails\n",
        "\n",
        "def make_Dictionary(root_dir):\n",
        "  #instantiate an empty list\n",
        "  word_list = [] \n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #consists of emails contained in the folder at the given path\n",
        "  for mail in emails:\n",
        "  #open mail files one by one by iterating over the folder \n",
        "    with open(mail) as m: \n",
        "      #iterate through lines in the mail opened in previous line\n",
        "      for line in m: \n",
        "        words = line.split() #split all the words in the mail and store it as items in a variable\n",
        "        word_list += words #add them to the list\n",
        "  word_dictionary = Counter(word_list) #A Counter is a dict subclass for counting hashable objects\n",
        "  word_to_remove = list(word_dictionary) #iterates over dictionary list\n",
        "\n",
        "  for item in word_to_remove: #checks if an item is non-alphabetic (numbers and symbols) and deletes it\n",
        "    if item.isalpha() == False:\n",
        "      del word_dictionary[item] \n",
        "    elif len(item) == 1: #deletes one letter words \n",
        "      del word_dictionary[item]\n",
        "  word_dictionary = word_dictionary.most_common(3000) #Return a list of the n most common elements and their counts from the most common to the least\n",
        "  return word_dictionary#create a list of the words \n",
        "  # Dictionary can be seen by print command below\n",
        "  \n",
        "#It contains the letters and their frequency in the decreasing order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJo98LdS8Cph",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 : Extracting Features and Corresponding label matrix\n",
        "\n",
        "With the help of dictionary we create a label and frequency matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lW3EOneqeH9",
        "colab_type": "text"
      },
      "source": [
        "The below python code will generate a feature vector matrix whose rows denote 700 files of training set and columns denote 3000 words of dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W1cnu8zdZ9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function extracts feature columns and populates their values \n",
        "#Feature Matrix has  3000 comumns and rows are equal to the number of email files.\n",
        "# The function also analyzes the File Names of each email file and decides if it's a Spame or not based on the naming convention.\n",
        "# Based on this the function also creates the Labelled Data Column. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkTENYUSrXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is used to extract the training dataset as well as the testing dataset and returns the Feature Dataset and the Label column\n",
        "\n",
        "def extract_features(mail_dir):\n",
        "  mailfolder = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(mailfolder),3000))\n",
        "  train_labels = np.zeros(len(mailfolder))\n",
        "  count = 1; #instantiate a counter\n",
        "  mailID = 0; #instatiate document variable\n",
        "  for mail in mailfolder: #iterates through each mail file\n",
        "    with open(mail) as fi: #open the mail file\n",
        "      for i, line in enumerate(fi): #iterate through each line of the email\n",
        "        if i ==2: # starts from 3rd line of the mail because text starts from there\n",
        "          words = line.split() #split the line into words\n",
        "          for word in words: #iterates through each and every word\n",
        "            wordID = 0 #set word counter to zero\n",
        "            for i, d in enumerate(word_dictionary): #goes through the dictionary of 3000 most common words\n",
        "              if d[0] == word:  #if the word is from the dictionary above then add it to feature matrix\n",
        "                wordID = i\n",
        "                #mailID -> Row id for 700 mails; wordID ->  column for 3000 most common words\n",
        "                features_matrix[mailID,wordID] = words.count(word) #feature matrix consists of 700 mails as rows and 3000 common words as columns \n",
        "     \n",
        "     #This part of code tests for the spam mails by testing if it contains \"spmsg\" in its mail body\n",
        "      train_labels[mailID] = 0;\n",
        "      filepathTokens = mail.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"): #checking if the text file is a spam or no\n",
        "        train_labels[mailID] = 1; #increment  row label by 1 \n",
        "        count = count + 1 #count of spam files\n",
        "      mailID = mailID + 1\n",
        "  return features_matrix, train_labels #returns a feature matrix (700 rows * 3000 coumns) with labels\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yBGuapOeTjM",
        "colab_type": "text"
      },
      "source": [
        "# Training and predicting with sklearn Naive Bayes\n",
        "\n",
        "The data-set used here, is split into a training set and a test set containing 702 mails and 260 mails respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys2_IaRqeSZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The section is the main Program that calls the above two functions and gets executed first.\n",
        "# First it \"trains\" the model using model.fit function and Training Dataset. \n",
        "#After that it scores the Test Data set by running the Trained Model with the Test Data set.\n",
        "# At the end it prints the model performance in terms of accuracy score.\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxAuq3wweNob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9ee1139b-41b7-4c1a-b693-40df8ecdacdc"
      },
      "source": [
        "#Give the data path train-mails and test-mails and store in Training and Testing variables respectively\n",
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML Algorithms/CA02/Naive_Bayes/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML Algorithms/CA02/Naive_Bayes/test-mails'\n",
        "\n",
        "# Create a dictionary of words with its frequency\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "# Prepare feature vectors per training mail and its labels\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR) #feature matrix for training data\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR) # feature matrix testing data\n",
        "\n",
        "#using Gaussian Naive Bayes Algorithm\n",
        "model = GaussianNB()\n",
        "\n",
        "#Training Naive bayes classifier\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels)\n",
        "print (\"Training completed\")\n",
        "\n",
        "#Test the unseen mails for Spam\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "\n",
        "#print accuracy of the model\n",
        "# Accuracy score is just percentage of correct predictions\n",
        "print (accuracy_score(test_labels, predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HBcTHclUKDD",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "[SPAM Email filtering](https://https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html)\n",
        "\n",
        "[OS module in Python](https://https://pythonprogramming.net/python-3-os-module/)\n",
        "\n",
        "[Enumerate Function](https://https://www.geeksforgeeks.org/enumerate-in-python/)"
      ]
    }
  ]
}
